# UpgradeSchema Control File (Default)
dbDriver=oracle.jdbc.driver.OracleDriver

# Conversion needs the database connection details
dbURL=PUT_YOUR_URL_HERE
dbUser=PUT_YOUR_USERNAME_HERE
dbPass=PUT_YOUR_PASSWORD_HERE

## select one conversion for content_resource table
## FileSizeResourcesConversion adds columns for the new quota query and the resource-type query (used by OSP)
## Type1BlobResourceConversion does all of that plus switching from XML serialization to binary-entity serialization

#convert.0=FileSizeResourcesConversion
#convert.0.handler.class=org.sakaiproject.content.impl.serialize.impl.conversion.FileSizeResourcesConversionHandler
#convert.0.create.migrate.table.count=3
#convert.0.create.migrate.table.0=create table CONTENT_RES_FSREGISTER ( id VARCHAR2(1024), status VARCHAR2(99) )
#convert.0.create.migrate.table.1=create index CONTENT_RES_FSREGISTER_id_idx on CONTENT_RES_FSREGISTER(id)
#convert.0.create.migrate.table.2=create index CONTENT_RES_FSREGISTER_st_idx on CONTENT_RES_FSREGISTER(status)
#convert.0.drop.migrate.table=drop table CONTENT_RES_FSREGISTER
#convert.0.check.migrate.table=select count(*) from CONTENT_RES_FSREGISTER where status <> 'done'
#convert.0.select.next.batch=select id from CONTENT_RES_FSREGISTER where status = 'pending' and rownum <= 100
#convert.0.complete.next.batch=update CONTENT_RES_FSREGISTER set status = 'done' where id = ?
#convert.0.mark.next.batch=update CONTENT_RES_FSREGISTER set status = 'locked' where id = ?
#convert.0.populate.migrate.table=insert into CONTENT_RES_FSREGISTER (id,status) select RESOURCE_ID, 'pending' from CONTENT_RESOURCE where resource_id not in (select id from CONTENT_RES_FSREGISTER)
#convert.0.select.record=select XML from CONTENT_RESOURCE where RESOURCE_ID = ?
#convert.0.select.validate.record=select XML from CONTENT_RESOURCE where RESOURCE_ID = ?
#convert.0.update.record=update CONTENT_RESOURCE set CONTEXT = ?, FILE_SIZE = ?, RESOURCE_TYPE_ID = ? where RESOURCE_ID = ? 
#convert.0.new.columns.names=CONTEXT,FILE_SIZE,RESOURCE_TYPE_ID
#convert.0.new.columns.types=VARCHAR2(99), NUMBER(18), VARCHAR2(255)
#convert.0.new.columns.qualifiers=default null, default null, default null
#convert.0.new.columns.add=alter table CONTENT_RESOURCE add <name> <type> <qualifier>
#convert.0.new.columns.test=select column_name from user_tab_columns where table_name = 'CONTENT_RESOURCE' and column_name = '<name>'
#convert.0.create.error.table=create table CONTENT_CONVERSION_ERRORS ( entity_id VARCHAR2(255), conversion VARCHAR2(255), error_description VARCHAR2(1024), report_time TIMESTAMP default LOCALTIMESTAMP )
#convert.0.report.error=insert into CONTENT_CONVERSION_ERRORS (entity_id,conversion,error_description) values (?,?,?)
#convert.0.verify.error.table=select column_name from user_tab_columns where table_name = 'CONTENT_CONVERSION_ERRORS'
#convert.0.early.termination.signal=quit.txt

convert.0=Type1BlobResourceConversion
convert.0.handler.class=org.sakaiproject.content.impl.serialize.impl.conversion.Type1BlobResourcesConversionHandler
convert.0.create.migrate.table.count=0
#convert.0.create.migrate.table.0=create table CONTENT_RES_T1REGISTER ( id VARCHAR2(1024), status VARCHAR2(99) )
#convert.0.create.migrate.table.1=create index CONTENT_RES_T1REGISTER_id_idx on CONTENT_RES_T1REGISTER(id)
#convert.0.create.migrate.table.2=create index CONTENT_RES_T1REGISTER_st_idx on CONTENT_RES_T1REGISTER(status)
convert.0.drop.migrate.table.count=1
convert.0.drop.migrate.table.0=drop table CONTENT_RES_T1REGISTER
#convert.0.drop.migrate.table.1=create index  CONTENT_RESOURCE_BLOB_IDX on CONTENT_RESOURCE(BINARY_ENTITY, 0)
#convert.0.drop.migrate.table.2=update CONTENT_RESOURCE set XML = NULL where BINARY_ENTITY is not NULL
convert.0.check.migrate.table=select count(*) from CONTENT_RES_T1REGISTER  where status <> 'done'
convert.0.select.next.batch=select id from CONTENT_RES_T1REGISTER where status = 'pending' and rownum <= 100
convert.0.complete.next.batch=update CONTENT_RES_T1REGISTER set status = 'done' where id = ?
convert.0.mark.next.batch=update CONTENT_RES_T1REGISTER set status = 'locked' where id = ?
#convert.0.populate.migrate.table=insert into CONTENT_RES_T1REGISTER (id,status) select RESOURCE_ID, 'pending' from CONTENT_RESOURCE where BINARY_ENTITY is NULL and XML is not null and resource_id not in (select id from CONTENT_RES_T1REGISTER)
convert.0.select.record=select XML from CONTENT_RESOURCE where RESOURCE_ID = ?
convert.0.select.validate.record=select BINARY_ENTITY from CONTENT_RESOURCE where RESOURCE_ID = ?
convert.0.update.record=update CONTENT_RESOURCE set CONTEXT = ?, FILE_SIZE = ?, BINARY_ENTITY = ?, RESOURCE_TYPE_ID = ? where RESOURCE_ID = ? 
convert.0.new.columns.names=CONTEXT,FILE_SIZE,RESOURCE_TYPE_ID,BINARY_ENTITY
convert.0.new.columns.types=VARCHAR2(99),NUMBER(18),VARCHAR2(255),BLOB
convert.0.new.columns.qualifiers=default null,default null,default null,default null  
convert.0.new.columns.add=alter table CONTENT_RESOURCE add <name> <type> <qualifier>
convert.0.new.columns.test=select column_name from user_tab_columns where table_name = 'CONTENT_RESOURCE' and column_name = '<name>'
convert.0.create.error.table=create table CONTENT_CONVERSION_ERRORS ( entity_id VARCHAR2(255), conversion VARCHAR2(255), error_description VARCHAR2(1024), report_time TIMESTAMP default LOCALTIMESTAMP )
convert.0.report.error=insert into CONTENT_CONVERSION_ERRORS (entity_id,conversion,error_description) values (?,?,?)
convert.0.verify.error.table=select column_name from user_tab_columns where table_name = 'CONTENT_CONVERSION_ERRORS'
convert.0.early.termination.signal=quit.txt

## select one conversion for content_resource_delete table
## FileSizeResourcesConversion adds and populates columns for the new quota query and the resource-type query (used by OSP)
## Type1BlobResourceConversion does all of that plus switching from XML serialization to binary-entity serialization

#convert.5=FileSizeResourcesConversion
#convert.5.handler.class=org.sakaiproject.content.impl.serialize.impl.conversion.FileSizeResourcesConversionHandler
#convert.5.create.migrate.table.count=3
#convert.5.create.migrate.table.0=create table CONTENT_DEL_FSREGISTER ( id varchar2(1024), status varchar2(99) )
#convert.5.create.migrate.table.1=create unique index CONTENT_DEL_FSREGISTER_id_idx on CONTENT_DEL_FSREGISTER(id)
#convert.5.create.migrate.table.2=create index CONTENT_DEL_FSREGISTER_st_idx on CONTENT_DEL_FSREGISTER(status)
#convert.5.drop.migrate.table=drop table CONTENT_DEL_FSREGISTER
#convert.5.check.migrate.table=select count(*) from CONTENT_DEL_FSREGISTER where status <> 'done'
#convert.5.select.next.batch=select id from CONTENT_DEL_FSREGISTER where status = 'pending' and rownum <= 100
#convert.5.complete.next.batch=update CONTENT_DEL_FSREGISTER set status = 'done' where id = ?
#convert.5.mark.next.batch=update CONTENT_DEL_FSREGISTER set status = 'locked' where id = ?
#convert.5.populate.migrate.table=insert into CONTENT_DEL_FSREGISTER (id,status) select RESOURCE_ID, 'pending' from CONTENT_RESOURCE_DELETE where resource_id not in (select id from CONTENT_DEL_FSREGISTER)
#convert.5.select.record=select XML from CONTENT_RESOURCE_DELETE where RESOURCE_ID = ?
#convert.5.select.validate.record=select XML from CONTENT_RESOURCE_DELETE where RESOURCE_ID = ?
#convert.5.update.record=update CONTENT_RESOURCE_DELETE set CONTEXT = ?, FILE_SIZE = ?, RESOURCE_TYPE_ID = ? where RESOURCE_ID = ? 
#convert.5.new.columns.names=CONTEXT,FILE_SIZE,RESOURCE_TYPE_ID
#convert.5.new.columns.types=VARCHAR2(99), NUMBER(18), VARCHAR2(255)
#convert.5.new.columns.qualifiers=default null, default null, default null
#convert.5.new.columns.add=alter table CONTENT_RESOURCE_DELETE add <name> <type> <qualifier>
#convert.5.new.columns.test=select column_name from user_tab_columns where table_name = 'CONTENT_RESOURCE_DELETE' and column_name = '<name>'
#convert.5.create.error.table=create table CONTENT_CONVERSION_ERRORS ( entity_id VARCHAR2(255), conversion VARCHAR2(255), error_description VARCHAR2(1024), report_time TIMESTAMP default LOCALTIMESTAMP )
#convert.5.report.error=insert into CONTENT_CONVERSION_ERRORS (entity_id,conversion,error_description) values (?,?,?)
#convert.5.verify.error.table=select column_name from user_tab_columns where table_name = 'CONTENT_CONVERSION_ERRORS'
#convert.5.early.termination.signal=quit.txt

convert.5=Type1BlobResourceConversion
convert.5.handler.class=org.sakaiproject.content.impl.serialize.impl.conversion.Type1BlobResourcesConversionHandler
convert.5.create.migrate.table.count=0
#convert.5.create.migrate.table.0=create table CONTENT_DEL_T1REGISTER ( id varchar2(1024), status varchar2(99) )
#convert.5.create.migrate.table.1=create index CONTENT_DEL_T1REGISTER_id_idx on CONTENT_DEL_T1REGISTER(id)
#convert.5.create.migrate.table.2=create index CONTENT_DEL_T1REGISTER_st_idx on CONTENT_DEL_T1REGISTER(status)
convert.5.drop.migrate.table.count=0
#convert.5.drop.migrate.table.0=drop table CONTENT_DEL_T1REGISTER
#convert.5.drop.migrate.table.1=update CONTENT_RESOURCE_DELETE set XML = NULL where BINARY_ENTITY is not NULL
convert.5.check.migrate.table=select count(*) from CONTENT_DEL_T1REGISTER  where status <> 'done'
convert.5.select.next.batch=select id from CONTENT_DEL_T1REGISTER where status = 'pending' and rownum <= 100
convert.5.complete.next.batch=update CONTENT_DEL_T1REGISTER set status = 'done' where id = ?
convert.5.mark.next.batch=update CONTENT_DEL_T1REGISTER set status = 'locked' where id = ?
#convert.5.populate.migrate.table=insert into CONTENT_DEL_T1REGISTER (id,status) select RESOURCE_ID, 'pending' from CONTENT_RESOURCE_DELETE where BINARY_ENTITY is NULL and XML is not null and resource_id not in (select id from CONTENT_DEL_T1REGISTER)
convert.5.select.record=select XML from CONTENT_RESOURCE_DELETE where RESOURCE_ID = ?
convert.5.select.validate.record=select BINARY_ENTITY from CONTENT_RESOURCE_DELETE where RESOURCE_ID = ?
convert.5.update.record=update CONTENT_RESOURCE_DELETE set CONTEXT = ?, FILE_SIZE = ?, BINARY_ENTITY = ?, RESOURCE_TYPE_ID = ? where RESOURCE_ID = ? 
convert.5.new.columns.names=CONTEXT,FILE_SIZE,RESOURCE_TYPE_ID,BINARY_ENTITY
convert.5.new.columns.types=VARCHAR2(99),NUMBER(18),VARCHAR2(255),BLOB
convert.5.new.columns.qualifiers=default null,default null,default null,default null  
convert.5.new.columns.add=alter table CONTENT_RESOURCE_DELETE add <name> <type> <qualifier>
convert.5.new.columns.test=select column_name from user_tab_columns where table_name = 'CONTENT_RESOURCE_DELETE' and column_name = '<name>'
convert.5.create.error.table=create table CONTENT_CONVERSION_ERRORS ( entity_id VARCHAR2(255), conversion VARCHAR2(255), error_description VARCHAR2(1024), report_time TIMESTAMP default LOCALTIMESTAMP )
convert.5.report.error=insert into CONTENT_CONVERSION_ERRORS (entity_id,conversion,error_description) values (?,?,?)
convert.5.verify.error.table=select column_name from user_tab_columns where table_name = 'CONTENT_CONVERSION_ERRORS'
convert.5.early.termination.signal=quit.txt

## convert to binary-entity serialization for content_collection table
## comment out this step unless you are switching from XML to binary-entity serialization

convert.1=Type1BlobCollectionConversion
convert.1.handler.class=org.sakaiproject.content.impl.serialize.impl.conversion.Type1BlobCollectionConversionHandler
convert.1.create.migrate.table.count=0
#convert.1.create.migrate.table.0=create table CONTENT_COL_T1REGISTER ( id VARCHAR2(1024), status VARCHAR2(99) )
#convert.1.create.migrate.table.1=create index CONTENT_COL_T1REGISTER_id_idx on CONTENT_COL_T1REGISTER(id)
#convert.1.create.migrate.table.2=create index CONTENT_COL_T1REGISTER_st_idx on CONTENT_COL_T1REGISTER(status)
convert.1.drop.migrate.table.count=0
#convert.1.drop.migrate.table.0=drop table CONTENT_COL_T1REGISTER
#convert.1.drop.migrate.table.1=update CONTENT_COLLECTION set XML = NULL where BINARY_ENTITY is not NULL
convert.1.check.migrate.table=select count(*) from CONTENT_COL_T1REGISTER  where status <> 'done'
convert.1.select.next.batch=select id from CONTENT_COL_T1REGISTER where status = 'pending' and rownum <= 100
convert.1.complete.next.batch=update CONTENT_COL_T1REGISTER set status = 'done' where id = ?
convert.1.mark.next.batch=update CONTENT_COL_T1REGISTER set status = 'locked' where id = ?
#convert.1.populate.migrate.table=insert into CONTENT_COL_T1REGISTER (id,status) select COLLECTION_ID, 'pending' from CONTENT_COLLECTION where BINARY_ENTITY IS NULL and XML is not null and COLLECTION_ID not in (select id from CONTENT_COL_T1REGISTER)
convert.1.select.record=select XML from CONTENT_COLLECTION where COLLECTION_ID = ?
convert.1.select.validate.record=select BINARY_ENTITY from CONTENT_COLLECTION where COLLECTION_ID = ?
convert.1.update.record=update CONTENT_COLLECTION set BINARY_ENTITY = ?  where COLLECTION_ID = ?
convert.1.new.columns.names=BINARY_ENTITY
convert.1.new.columns.types=BLOB
convert.1.new.columns.qualifiers=default null
convert.1.new.columns.add=alter table CONTENT_COLLECTION add <name> <type> <qualifier>
convert.1.new.columns.test=select column_name from user_tab_columns where table_name = 'CONTENT_COLLECTION' and column_name = '<name>'
convert.1.verify.error.table=select column_name from user_tab_columns where table_name = 'CONTENT_CONVERSION_ERRORS'
convert.1.create.error.table=create table CONTENT_CONVERSION_ERRORS ( entity_id VARCHAR2(255), conversion VARCHAR2(255), error_description VARCHAR2(1024), report_time TIMESTAMP default LOCALTIMESTAMP )
convert.1.report.error=insert into CONTENT_CONVERSION_ERRORS (entity_id,conversion,error_description) values (?,?,?)
convert.1.early.termination.signal=quit.txt


